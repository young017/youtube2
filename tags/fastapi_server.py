#!/usr/bin/env python3
"""
1ë“± ìœ íŠœë²„ ë˜ê¸° FastAPI ì„œë²„
OpenAPI ìŠ¤í™ì„ ì‚¬ìš©í•˜ì—¬ REST APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.
"""

from fastapi import FastAPI, HTTPException, Depends, status, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import os
import json
from datetime import datetime
import sys
import os
import numpy as np
import pandas as pd
import re
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# Kaggle API import (í™˜ê²½ ë³€ìˆ˜ KAGGLE_USERNAME, KAGGLE_KEY ì‚¬ìš©)
from kaggle.api.kaggle_api_extended import KaggleApi

# YouTube API import
try:
    from googleapiclient.discovery import build
    YOUTUBE_API_AVAILABLE = True
except ImportError:
    YOUTUBE_API_AVAILABLE = False
    print("âš ï¸ googleapiclientê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install google-api-python-client'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# 2025ë…„ ë°ì´í„° ìºì‹œ (ì „ì—­ ë³€ìˆ˜)
df_2025_cache = None
cache_metadata = {
    'date_column': None,
    'category_column': None,
    'views_column': None,
    'video_id_column': None
}

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì˜ ë””ë ‰í† ë¦¬ì™€ ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
if script_dir not in sys.path:
    sys.path.insert(0, script_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from database import UserDatabase, db
from tags.tag_recommendation_model import TagRecommendationModel
from enrich_tags import run_pipeline
from openai import OpenAI

# ML ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
try:
    from catboost import CatBoostClassifier, CatBoostRegressor
    CATBOOST_AVAILABLE = True
except ImportError:
    CATBOOST_AVAILABLE = False
    print("âš ï¸ CatBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False
    print("âš ï¸ LightGBMì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

try:
    import xgboost as xgb
    import joblib
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    print("âš ï¸ XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# OpenAI API í‚¤ ì„¤ì •
# í™˜ê²½ ë³€ìˆ˜ì—ì„œë§Œ í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤ (ë³´ì•ˆìƒ í•˜ë“œì½”ë”©í•˜ì§€ ì•ŠìŒ)
openai_api_key = os.environ.get("OPENAI_API_KEY")
if not openai_api_key:
    print("âš ï¸ ê²½ê³ : OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”: export OPENAI_API_KEY='your-api-key-here'")
else:
    print("âœ… OpenAI API í‚¤ê°€ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="1ë“± ìœ íŠœë²„ ë˜ê¸° API",
    description="YouTube ì˜ìƒ ë°ì´í„° ë¶„ì„ ë° íƒœê·¸ ì¶”ì²œ API",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# JSON ì¸ì½”ë”© ì„¤ì • (í•œê¸€ ì§€ì›)
import json
from fastapi.encoders import jsonable_encoder
from fastapi.responses import JSONResponse as FastAPIJSONResponse

class UTF8JSONResponse(FastAPIJSONResponse):
    """UTF-8 ì¸ì½”ë”©ì„ ë³´ì¥í•˜ëŠ” JSON ì‘ë‹µ í´ë˜ìŠ¤"""
    def render(self, content: Any) -> bytes:
        return json.dumps(
            jsonable_encoder(content),
            ensure_ascii=False,
            allow_nan=False,
            indent=None,
            separators=(",", ":"),
        ).encode("utf-8")

# JSONResponseì˜ ensure_ascii ì„¤ì •ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ì‘ë‹µ í´ë˜ìŠ¤
def create_json_response(data: dict, status_code: int = 200):
    """í•œê¸€ ì¸ì½”ë”©ì„ ì˜¬ë°”ë¥´ê²Œ ì²˜ë¦¬í•˜ëŠ” JSON ì‘ë‹µ ìƒì„±"""
    return UTF8JSONResponse(content=data, status_code=status_code)

# CORS ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ë°ì´í„°ë² ì´ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
user_db = db

# íƒœê·¸ ì¶”ì²œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
tag_model = None

# ì¡°íšŒìˆ˜ ì˜ˆì¸¡ ëª¨ë¸ ìºì‹œ (ì¹´í…Œê³ ë¦¬ë³„)
prediction_models = {}

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)
def get_model_base_path():
    """ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì°¾ê¸° (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„)"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    current_dir = os.getcwd()
    
    possible_paths = [
        os.path.join(project_root, "ëª¨ë¸"),  # í”„ë¡œì íŠ¸ ë£¨íŠ¸/ëª¨ë¸
        os.path.join(script_dir, "ëª¨ë¸"),  # tags/ëª¨ë¸
        "/app/ëª¨ë¸",  # Railway ë°°í¬ í™˜ê²½ (ë£¨íŠ¸)
        "/app/tags/ëª¨ë¸",  # Railway ë°°í¬ í™˜ê²½ (tags ë””ë ‰í† ë¦¬)
        os.path.join(current_dir, "ëª¨ë¸"),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬/ëª¨ë¸
        os.path.join(current_dir, "tags", "ëª¨ë¸"),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬/tags/ëª¨ë¸
        "ëª¨ë¸",  # ìƒëŒ€ ê²½ë¡œ
    ]
    
    print(f"ğŸ” ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²€ìƒ‰ ì‹œì‘...")
    print(f"   script_dir: {script_dir}")
    print(f"   project_root: {project_root}")
    print(f"   current_dir: {current_dir}")
    
    for path in possible_paths:
        abs_path = os.path.abspath(path) if not os.path.isabs(path) else path
        exists = os.path.exists(abs_path)
        is_dir = os.path.isdir(abs_path) if exists else False
        print(f"   ì‹œë„: {abs_path} (ì¡´ì¬: {exists}, ë””ë ‰í† ë¦¬: {is_dir})")
        
        if exists and is_dir:
            # ëª¨ë¸ íŒŒì¼ì´ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
            try:
                files = os.listdir(abs_path)
                model_files = [f for f in files if f.endswith(('.cbm', '.pkl'))]
                print(f"      íŒŒì¼ ìˆ˜: {len(files)}, ëª¨ë¸ íŒŒì¼ ìˆ˜: {len(model_files)}")
                if model_files:
                    print(f"      ëª¨ë¸ íŒŒì¼ ì˜ˆì‹œ: {model_files[:3]}")
                    print(f"âœ… ëª¨ë¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {abs_path}")
                    return abs_path
            except Exception as e:
                print(f"      ë””ë ‰í† ë¦¬ ì½ê¸° ì‹¤íŒ¨: {e}")
    
    # ê¸°ë³¸ ê²½ë¡œ ë°˜í™˜ (ì¡´ì¬í•˜ì§€ ì•Šì•„ë„)
    default_path = os.path.join(project_root, "ëª¨ë¸")
    print(f"âš ï¸ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©: {default_path}")
    print(f"ğŸ’¡ Railway ë°°í¬ ì‹œ Git LFS íŒŒì¼ì´ ì œëŒ€ë¡œ ë‹¤ìš´ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    print(f"ğŸ’¡ Railway ë¡œê·¸ì—ì„œ 'git lfs pull' ëª…ë ¹ì´ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    return default_path

MODEL_BASE_PATH = get_model_base_path()

def load_prediction_models(category: str):
    """ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜/íšŒê·€ ëª¨ë¸ ë¡œë“œ"""
    if category in prediction_models:
        return prediction_models[category]
    
    category_int = int(category)
    models = {}
    
    print(f"ğŸ” ì¹´í…Œê³ ë¦¬ {category} ëª¨ë¸ ë¡œë“œ ì‹œì‘")
    print(f"ğŸ” MODEL_BASE_PATH: {MODEL_BASE_PATH}")
    print(f"ğŸ” MODEL_BASE_PATH ì¡´ì¬ ì—¬ë¶€: {os.path.exists(MODEL_BASE_PATH)}")
    
    try:
        # ì¹´í…Œê³ ë¦¬ë³„ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
        if category_int in [1, 15, 19]:  # CatBoost
            if not CATBOOST_AVAILABLE:
                raise ImportError("CatBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            cls_model_path = os.path.join(MODEL_BASE_PATH, f"catboost_model_{category_int}_class.cbm")
            reg_model_path = os.path.join(MODEL_BASE_PATH, f"catboost_model_{category_int}.cbm")
            print(f"ğŸ” CatBoost ëª¨ë¸ ê²½ë¡œ:")
            print(f"   - ë¶„ë¥˜: {cls_model_path} (ì¡´ì¬: {os.path.exists(cls_model_path)})")
            print(f"   - íšŒê·€: {reg_model_path} (ì¡´ì¬: {os.path.exists(reg_model_path)})")
            
            if os.path.exists(cls_model_path) and os.path.exists(reg_model_path):
                cls_model = CatBoostClassifier()
                cls_model.load_model(cls_model_path)
                reg_model = CatBoostRegressor()
                reg_model.load_model(reg_model_path)
                models = {
                    'cls': cls_model,
                    'reg': reg_model,
                    'type': 'catboost'
                }
                
        elif category_int in [10, 22, 24, 26]:  # LightGBM
            if not LIGHTGBM_AVAILABLE:
                raise ImportError("LightGBMì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            cls_model_path = os.path.join(MODEL_BASE_PATH, f"lgbm_model_{category_int}_class.pkl")
            reg_model_path = os.path.join(MODEL_BASE_PATH, f"lgbm_model_{category_int}.pkl")
            print(f"ğŸ” LightGBM ëª¨ë¸ ê²½ë¡œ:")
            print(f"   - ë¶„ë¥˜: {cls_model_path} (ì¡´ì¬: {os.path.exists(cls_model_path)})")
            print(f"   - íšŒê·€: {reg_model_path} (ì¡´ì¬: {os.path.exists(reg_model_path)})")
            
            if os.path.exists(cls_model_path) and os.path.exists(reg_model_path):
                print(f"ğŸ“¦ ëª¨ë¸ íŒŒì¼ ë¡œë”© ì‹œì‘...")
                cls_model = joblib.load(cls_model_path)
                reg_model = joblib.load(reg_model_path)
                models = {
                    'cls': cls_model,
                    'reg': reg_model,
                    'type': 'lightgbm'
                }
                print(f"ğŸ“¦ ëª¨ë¸ íŒŒì¼ ë¡œë”© ì™„ë£Œ")
            else:
                # ë””ë ‰í† ë¦¬ ë‚´ìš© í™•ì¸
                if os.path.exists(MODEL_BASE_PATH):
                    print(f"ğŸ“‚ ëª¨ë¸ ë””ë ‰í† ë¦¬ ë‚´ìš©:")
                    for file in os.listdir(MODEL_BASE_PATH):
                        if f"_{category_int}" in file:
                            print(f"   - {file}")
                
        elif category_int in [17, 20, 23, 28]:  # XGBoost
            if not XGBOOST_AVAILABLE:
                raise ImportError("XGBoostê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            cls_model_path = os.path.join(MODEL_BASE_PATH, f"xgb_model_{category_int}_class.pkl")
            reg_model_path = os.path.join(MODEL_BASE_PATH, f"xgb_model_{category_int}.pkl")
            print(f"ğŸ” XGBoost ëª¨ë¸ ê²½ë¡œ:")
            print(f"   - ë¶„ë¥˜: {cls_model_path} (ì¡´ì¬: {os.path.exists(cls_model_path)})")
            print(f"   - íšŒê·€: {reg_model_path} (ì¡´ì¬: {os.path.exists(reg_model_path)})")
            
            if os.path.exists(cls_model_path) and os.path.exists(reg_model_path):
                cls_model = joblib.load(cls_model_path)
                reg_model = joblib.load(reg_model_path)
                models = {
                    'cls': cls_model,
                    'reg': reg_model,
                    'type': 'xgboost'
                }
        
        if models:
            prediction_models[category] = models
            print(f"âœ… ì¹´í…Œê³ ë¦¬ {category} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        else:
            print(f"âš ï¸ ì¹´í…Œê³ ë¦¬ {category} ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            if os.path.exists(MODEL_BASE_PATH):
                print(f"ğŸ“‚ ëª¨ë¸ ë””ë ‰í† ë¦¬ ì „ì²´ ë‚´ìš©:")
                for file in os.listdir(MODEL_BASE_PATH):
                    print(f"   - {file}")
            
    except Exception as e:
        print(f"âŒ ì¹´í…Œê³ ë¦¬ {category} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        import traceback
        print(f"âŒ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
    
    return models

def predict_views(category: str, input_df: pd.DataFrame) -> Dict[str, Any]:
    """ì¹´í…Œê³ ë¦¬ë³„ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¡°íšŒìˆ˜ ì˜ˆì¸¡"""
    category_int = int(category)
    
    print(f"ğŸ” predict_views ì‹œì‘ - ì¹´í…Œê³ ë¦¬: {category}")
    
    # ëª¨ë¸ ë¡œë“œ
    models = load_prediction_models(category)
    print(f"ğŸ” ëª¨ë¸ ë¡œë“œ ê²°ê³¼: {models}")
    
    if not models:
        error_msg = f"ì¹´í…Œê³ ë¦¬ {category} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. MODEL_BASE_PATH: {MODEL_BASE_PATH}"
        print(f"âŒ {error_msg}")
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail=error_msg
        )
    
    cls_model = models['cls']
    reg_model = models['reg']
    model_type = models['type']
    
    print(f"ğŸ” ëª¨ë¸ íƒ€ì…: {model_type}")
    print(f"ğŸ” ë¶„ë¥˜ ëª¨ë¸: {type(cls_model)}")
    print(f"ğŸ” íšŒê·€ ëª¨ë¸: {type(reg_model)}")
    
    try:
        # ë¶„ë¥˜ ëª¨ë¸ë¡œ pred_popular_prob ìƒì„±
        print(f"ğŸ” ë¶„ë¥˜ ëª¨ë¸ feature ì¶”ì¶œ ì‹œì‘...")
        if model_type == 'catboost':
            cls_features = cls_model.feature_names_
        elif model_type == 'lightgbm':
            # LightGBM: feature_name_ ë˜ëŠ” feature_names_ ì‚¬ìš©
            if hasattr(cls_model, 'feature_name_'):
                cls_features = cls_model.feature_name_
            elif hasattr(cls_model, 'feature_names_'):
                cls_features = cls_model.feature_names_
            else:
                raise AttributeError("LightGBM ëª¨ë¸ì—ì„œ feature_name_ ë˜ëŠ” feature_names_ ì†ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:  # xgboost
            # XGBoost: get_booster() ì‚¬ìš© ì‹œë„, ì—†ìœ¼ë©´ ì§ì ‘ feature_names_ ì‚¬ìš©
            try:
                cls_features = cls_model.get_booster().feature_names
            except:
                if hasattr(cls_model, 'feature_names_'):
                    cls_features = cls_model.feature_names_
                else:
                    raise AttributeError("XGBoost ëª¨ë¸ì—ì„œ feature_namesë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ëˆ„ë½ëœ í”¼ì²˜ëŠ” 0ìœ¼ë¡œ ì±„ìš°ê¸°
        print("=" * 80)
        print("ğŸ” [ë¶„ë¥˜ ëª¨ë¸] Feature í™•ì¸")
        print("=" * 80)
        print(f"ğŸ” ë¶„ë¥˜ ëª¨ë¸ feature ê°œìˆ˜: {len(cls_features)}")
        print(f"ğŸ” ë¶„ë¥˜ ëª¨ë¸ features: {cls_features}")
        
        missing_features = []
        for f in cls_features:
            if f not in input_df.columns:
                input_df[f] = 0
                missing_features.append(f)
        if missing_features:
            print(f"âš ï¸ ëˆ„ë½ëœ featureë¥¼ 0ìœ¼ë¡œ ì±„ì›€: {missing_features}")
        
        print("\nğŸ“Š [ë¶„ë¥˜ ëª¨ë¸] ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
        print(f"ğŸ“Š ë¶„ë¥˜ ëª¨ë¸ ì…ë ¥ ì»¬ëŸ¼ ({len(input_df[cls_features].columns)}ê°œ): {input_df[cls_features].columns.tolist()}")
        print(f"\nğŸ“Š ë¶„ë¥˜ ëª¨ë¸ ì…ë ¥ ë°ì´í„°:")
        print(input_df[cls_features])
        
        # pred_popular_prob ê³„ì‚°
        print("\n" + "=" * 80)
        print("ğŸ” [ë¶„ë¥˜ ëª¨ë¸] predict_proba ì‹¤í–‰ ì‹œì‘...")
        print("=" * 80)
        try:
            if model_type == 'catboost':
                proba_result = cls_model.predict_proba(input_df[cls_features])
                print(f"ğŸ“Š CatBoost predict_proba ê²°ê³¼ shape: {proba_result.shape}")
                print(f"ğŸ“Š CatBoost predict_proba ê²°ê³¼: {proba_result}")
                input_df['pred_popular_prob'] = proba_result[:, 1]
            elif model_type == 'lightgbm':
                proba_result = cls_model.predict_proba(input_df[cls_features])
                print(f"ğŸ“Š LightGBM predict_proba ê²°ê³¼ shape: {proba_result.shape}")
                print(f"ğŸ“Š LightGBM predict_proba ê²°ê³¼: {proba_result}")
                print(f"ğŸ“Š LightGBM predict_proba ê²°ê³¼ (ìƒì„¸): í´ë˜ìŠ¤ 0 í™•ë¥ ={proba_result[0][0]:.6f}, í´ë˜ìŠ¤ 1 í™•ë¥ ={proba_result[0][1]:.6f}")
                input_df['pred_popular_prob'] = proba_result[:, 1]
            else:  # xgboost
                proba_result = cls_model.predict_proba(input_df[cls_features])
                print(f"ğŸ“Š XGBoost predict_proba ê²°ê³¼ shape: {proba_result.shape}")
                print(f"ğŸ“Š XGBoost predict_proba ê²°ê³¼: {proba_result}")
                input_df['pred_popular_prob'] = proba_result[:, 1]
            
            print("\n" + "=" * 80)
            print("âœ… [ë¶„ë¥˜ ëª¨ë¸] pred_popular_prob ê³„ì‚° ì™„ë£Œ")
            print("=" * 80)
            pred_value = input_df['pred_popular_prob'].iloc[0]
            print(f"ğŸ“Š pred_popular_prob ê°’: {pred_value}")
            print(f"ğŸ“Š pred_popular_prob íƒ€ì…: {type(pred_value)}")
            print(f"ğŸ“Š pred_popular_prob (í¼ì„¼íŠ¸): {pred_value * 100:.2f}%")
            print("=" * 80 + "\n")
        except Exception as e:
            print("\n" + "=" * 80)
            print("âŒ [ë¶„ë¥˜ ëª¨ë¸] ì˜ˆì¸¡ ì‹¤íŒ¨")
            print("=" * 80)
            print(f"âŒ ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}")
            import traceback
            print(f"âŒ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
            print("=" * 80 + "\n")
            raise
        
        # íšŒê·€ ëª¨ë¸ë¡œ ì¡°íšŒìˆ˜ ì˜ˆì¸¡
        print("=" * 80)
        print("ğŸ” [íšŒê·€ ëª¨ë¸] Feature í™•ì¸")
        print("=" * 80)
        if model_type == 'catboost':
            reg_features = reg_model.feature_names_
        elif model_type == 'lightgbm':
            # LightGBM: feature_name_ ë˜ëŠ” feature_names_ ì‚¬ìš©
            if hasattr(reg_model, 'feature_name_'):
                reg_features = reg_model.feature_name_
            elif hasattr(reg_model, 'feature_names_'):
                reg_features = reg_model.feature_names_
            else:
                raise AttributeError("LightGBM íšŒê·€ ëª¨ë¸ì—ì„œ feature_name_ ë˜ëŠ” feature_names_ ì†ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:  # xgboost
            # XGBoost: get_booster() ì‚¬ìš© ì‹œë„, ì—†ìœ¼ë©´ ì§ì ‘ feature_names_ ì‚¬ìš©
            try:
                reg_features = reg_model.get_booster().feature_names
            except:
                if hasattr(reg_model, 'feature_names_'):
                    reg_features = reg_model.feature_names_
                else:
                    raise AttributeError("XGBoost íšŒê·€ ëª¨ë¸ì—ì„œ feature_namesë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ” íšŒê·€ ëª¨ë¸ feature ê°œìˆ˜: {len(reg_features)}")
        print(f"ğŸ” íšŒê·€ ëª¨ë¸ features: {reg_features}")
        print(f"ğŸ” ì˜ˆìƒ features (11ê°œ): ['caption_available', 'pub_month', 'pub_day', 'pub_hour_sin', 'pub_hour_cos', 'pub_weekday_sin', 'pub_weekday_cos', 'duration_sec', 'definition', 'subscriber_count_log', 'pred_popular_prob']")
        
        # ëˆ„ë½ëœ í”¼ì²˜ëŠ” 0ìœ¼ë¡œ ì±„ìš°ê¸°
        missing_reg_features = []
        for f in reg_features:
            if f not in input_df.columns:
                input_df[f] = 0
                missing_reg_features.append(f)
        if missing_reg_features:
            print(f"âš ï¸ ëˆ„ë½ëœ featureë¥¼ 0ìœ¼ë¡œ ì±„ì›€: {missing_reg_features}")
        
        print("\nğŸ“Š [íšŒê·€ ëª¨ë¸] ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
        print(f"ğŸ“Š íšŒê·€ ëª¨ë¸ ì…ë ¥ ì»¬ëŸ¼ ({len(input_df[reg_features].columns)}ê°œ): {input_df[reg_features].columns.tolist()}")
        print(f"\nğŸ“Š íšŒê·€ ëª¨ë¸ ì…ë ¥ ë°ì´í„°:")
        print(input_df[reg_features])
        
        print("\n" + "=" * 80)
        print("ğŸ” [íšŒê·€ ëª¨ë¸] predict ì‹¤í–‰ ì‹œì‘...")
        print("=" * 80)
        
        # XGBoostì˜ ê²½ìš° input_dfë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•´ì•¼ í•  ìˆ˜ ìˆìŒ
        if model_type == 'xgboost' and category_int == 23:
            # ì¹´í…Œê³ ë¦¬ 23ì˜ ê²½ìš° íŠ¹ë³„ ì²˜ë¦¬
            input_df_for_pred = input_df[reg_features]
            print(f"ğŸ“Š XGBoost (ì¹´í…Œê³ ë¦¬ 23) - ì‚¬ìš©í•  ë°ì´í„° shape: {input_df_for_pred.shape}")
            y_pred_log = reg_model.predict(input_df_for_pred)
        else:
            print(f"ğŸ“Š {model_type} íšŒê·€ ëª¨ë¸ predict ì‹¤í–‰...")
            print(f"ğŸ“Š ì‚¬ìš©í•  ì»¬ëŸ¼: {reg_features}")
            y_pred_log = reg_model.predict(input_df[reg_features])
        
        print(f"âœ… [íšŒê·€ ëª¨ë¸] ì˜ˆì¸¡ ì™„ë£Œ")
        print(f"ğŸ“Š ì˜ˆì¸¡ê°’ (ë¡œê·¸ ìŠ¤ì¼€ì¼): {y_pred_log[0]:.6f}")
        print("=" * 80)
        
        # ì¹´í…Œê³ ë¦¬ë³„ ìŠ¤ì¼€ì¼ ì ìš©
        if category_int in [10, 23]:  # 100ë§Œ ë‹¨ìœ„
            y_pred = np.expm1(y_pred_log) * 1_000_000
            print(f"ğŸ“Š ìŠ¤ì¼€ì¼ ì ìš© (100ë§Œ ë‹¨ìœ„): {y_pred[0]:,.0f}")
        else:  # 10ë§Œ ë‹¨ìœ„
            y_pred = np.expm1(y_pred_log) * 100_000
            print(f"ğŸ“Š ìŠ¤ì¼€ì¼ ì ìš© (10ë§Œ ë‹¨ìœ„): {y_pred[0]:,.0f}")
        
        # ì‹¤ì œ ì‚¬ìš©ëœ ëª¨ë¸ íŒŒì¼ëª… ìƒì„±
        if category_int in [1, 15, 19]:  # CatBoost
            cls_model_file = f"catboost_model_{category_int}_class.cbm"
            reg_model_file = f"catboost_model_{category_int}.cbm"
        elif category_int in [10, 22, 24, 26]:  # LightGBM
            cls_model_file = f"lgbm_model_{category_int}_class.pkl"
            reg_model_file = f"lgbm_model_{category_int}.pkl"
        else:  # XGBoost
            cls_model_file = f"xgb_model_{category_int}_class.pkl"
            reg_model_file = f"xgb_model_{category_int}.pkl"
        
        # ëª¨ë¸ ì´ë¦„ ìƒì„± (í‘œì‹œìš©)
        model_type_names = {
            'catboost': 'CatBoost',
            'lightgbm': 'LightGBM',
            'xgboost': 'XGBoost'
        }
        cls_model_name = f"{model_type_names[model_type]} Classifier"
        reg_model_name = f"{model_type_names[model_type]} Regressor"
        
        return {
            'predicted_views': int(y_pred[0]),
            'pred_popular_prob': float(input_df['pred_popular_prob'].iloc[0]),
            'confidence': float(input_df['pred_popular_prob'].iloc[0]) * 100,
            'cls_model': cls_model_name,
            'reg_model': reg_model_name,
            'cls_model_file': cls_model_file,
            'reg_model_file': reg_model_file,
            'model_type': model_type
        }
        
    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        print(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

# Pydantic ëª¨ë¸ ì •ì˜
class UserRegister(BaseModel):
    email: str = Field(..., description="ì‚¬ìš©ì ì´ë©”ì¼")
    password: str = Field(..., min_length=6, description="ë¹„ë°€ë²ˆí˜¸ (ìµœì†Œ 6ì)")
    name: str = Field(..., description="ì‚¬ìš©ì ì´ë¦„")
    role: str = Field(..., description="ì‚¬ìš©ì ì—­í• ")
    profile_data: Optional[Dict[str, Any]] = Field(default={}, description="ì¶”ê°€ í”„ë¡œí•„ ë°ì´í„°")

class UserLogin(BaseModel):
    email: str = Field(..., description="ì‚¬ìš©ì ì´ë©”ì¼")
    password: str = Field(..., description="ë¹„ë°€ë²ˆí˜¸")

class UserLogout(BaseModel):
    session_token: str = Field(..., description="ì„¸ì…˜ í† í°")

class ProfileUpdate(BaseModel):
    profile_data: Dict[str, Any] = Field(..., description="ì—…ë°ì´íŠ¸í•  í”„ë¡œí•„ ë°ì´í„°")

class TagRecommendRequest(BaseModel):
    title: str = Field(..., description="ìœ íŠœë¸Œ ì˜ìƒ ì œëª©")
    top_k: int = Field(default=20, ge=1, le=50, description="ì¶”ì²œí•  íƒœê·¸ ê°œìˆ˜")
    method: str = Field(default="hybrid", description="ì¶”ì²œ ë°©ë²• (hybrid, sbert, similarity)")

class TagRefineRequest(BaseModel):
    title: str = Field(..., description="ìœ íŠœë¸Œ ì˜ìƒ ì œëª©")
    candidate_tags: Optional[List[str]] = Field(default=[], description="ìˆ˜ì •í•  í›„ë³´ íƒœê·¸ë“¤")

class APIResponse(BaseModel):
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None

class TagRecommendResponse(BaseModel):
    success: bool
    title: str
    recommended_tags: List[str]
    method: str
    similar_titles: List[Dict[str, Any]]

class TagRefineResponse(BaseModel):
    success: bool
    title: str
    original_candidate_tags: List[str]
    refined_tags: List[str]
    prompt: str

class TagEnrichRequest(BaseModel):
    title: str = Field(..., description="ìœ íŠœë¸Œ ì˜ìƒ ì œëª©")
    description: Optional[str] = Field(default="", description="ìœ íŠœë¸Œ ì˜ìƒ ì„¤ëª…")
    top_k: int = Field(default=15, ge=1, le=50, description="ì¶”ì²œí•  íƒœê·¸ ê°œìˆ˜")
    title_sim_threshold: float = Field(default=0.30, description="ì œëª© ìœ ì‚¬ë„ ì„ê³„ê°’")
    tag_abs_threshold: float = Field(default=0.30, description="íƒœê·¸ ìœ ì‚¬ë„ ì„ê³„ê°’")
    extra_k: int = Field(default=20, description="ì¶”ê°€ íƒœê·¸ ê°œìˆ˜")
    api_key: Optional[str] = Field(default=None, description="OpenAI API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)")

class TagEnrichResponse(BaseModel):
    success: bool
    title: str
    description: str
    candidates: List[str]
    scored: List[Dict[str, Any]]
    kept: List[str]
    dropped: List[str]
    final_tags: List[str]
    extra_tags: List[str]

class TitleGenerateRequest(BaseModel):
    keyword: str = Field(..., description="ì£¼ì œ í‚¤ì›Œë“œ")
    imageText: Optional[str] = Field(default="", description="ì´ë¯¸ì§€ ë‚´ìš© ìš”ì•½")
    n: int = Field(default=5, ge=1, le=10, description="ìƒì„±í•  ì œëª© ê°œìˆ˜")

class TitleGenerateResponse(BaseModel):
    success: bool
    titles: List[str]
    message: Optional[str] = None

class VideoCreateRequest(BaseModel):
    title: str = Field(..., description="ì˜ìƒ ì œëª©")
    category: str = Field(..., description="ì¹´í…Œê³ ë¦¬")
    length: float = Field(..., ge=0.01, description="ì˜ìƒ ê¸¸ì´ (ë¶„, ì†Œìˆ˜ì  ê°€ëŠ¥)")
    upload_time: Optional[str] = Field(default=None, description="ì—…ë¡œë“œ ì˜ˆì • ì‹œê°„")
    description: Optional[str] = Field(default=None, description="ì˜ìƒ ì„¤ëª…")
    thumbnail_image: Optional[str] = Field(default=None, description="ì¸ë„¤ì¼ ì´ë¯¸ì§€ (Base64)")
    has_subtitles: Optional[str] = Field(default=None, description="ìë§‰ ì œê³µ ì—¬ë¶€ (provided/not_provided)")
    video_quality: Optional[str] = Field(default=None, description="í•´ìƒë„ í’ˆì§ˆ (HD/SD)")
    subscriber_count: Optional[int] = Field(default=None, description="êµ¬ë…ììˆ˜")

def preprocess_input_data(request: VideoCreateRequest) -> pd.DataFrame:
    """ì‚¬ìš©ì ì…ë ¥ ë°ì´í„°ë¥¼ ëª¨ë¸ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ì „ì²˜ë¦¬"""
    # ì—…ë¡œë“œ ì˜ˆì • ì‹œê°„ íŒŒì‹±
    upload_time = request.upload_time
    if not upload_time:
        # ê¸°ë³¸ê°’ (í˜„ì¬ ì‹œê°„ + 1ì‹œê°„)
        dt = datetime.now()
        dt = dt.replace(hour=(dt.hour + 1) % 24)
    else:
        # datetime-local í˜•ì‹: YYYY-MM-DDTHH:mm
        dt = datetime.fromisoformat(upload_time)
        if dt.tzinfo:
            dt = dt.astimezone().replace(tzinfo=None)
    
    month = dt.month
    day = dt.day
    hour = dt.hour
    weekday_python = dt.weekday()  # Python: 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
    
    # ìš”ì¼ ë³€í™˜: Python weekday (0=ì›”, 6=ì¼) -> JavaScript/ì¼ë°˜ í˜•ì‹ (0=ì¼, 6=í† )
    # Python weekday + 1 -> modulo 7ë¡œ ë³€í™˜
    weekday = (weekday_python + 1) % 7  # 0=ì¼ìš”ì¼, 1=ì›”ìš”ì¼, ..., 6=í† ìš”ì¼
    
    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    # í•™ìŠµ ì‹œ subscriber_countëŠ” dropë˜ê³  subscriber_count_logë§Œ ì‚¬ìš©ë¨
    # ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” ì»¬ëŸ¼ëª…: duration_sec (duration ì•„ë‹˜!)
    df = pd.DataFrame({
        'duration_sec': [request.length * 60],  # ë¶„ì„ ì´ˆë¡œ ë³€í™˜
        'definition': [1 if request.video_quality == 'HD' else 0],
        'caption_available': [1 if request.has_subtitles == 'provided' else 0],
        'pub_month': [month],
        'pub_day': [day],
        'pub_hour_sin': [np.sin(2 * np.pi * hour / 24)],
        'pub_hour_cos': [np.cos(2 * np.pi * hour / 24)],
        'pub_weekday_sin': [np.sin(2 * np.pi * weekday / 7)],
        'pub_weekday_cos': [np.cos(2 * np.pi * weekday / 7)],
        'subscriber_count_log': [np.log1p(request.subscriber_count) if request.subscriber_count and request.subscriber_count > 0 else 0]
    })
    
    return df

class VideoResponse(BaseModel):
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None

def load_tag_model():
    """íƒœê·¸ ì¶”ì²œ ëª¨ë¸ ë¡œë“œ"""
    global tag_model
    try:
        # ì—¬ëŸ¬ ê²½ë¡œì—ì„œ ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        current_dir = os.getcwd()
        
        possible_paths = [
            os.path.join(script_dir, "tag_recommendation_model.pkl"),  # tags/tag_recommendation_model.pkl
            os.path.join(project_root, "tags", "tag_recommendation_model.pkl"),  # í”„ë¡œì íŠ¸ ë£¨íŠ¸/tags/tag_recommendation_model.pkl
            "/app/tags/tag_recommendation_model.pkl",  # Railway ë°°í¬ í™˜ê²½ (tags ë””ë ‰í† ë¦¬)
            "/app/tag_recommendation_model.pkl",  # Railway ë°°í¬ í™˜ê²½ (ë£¨íŠ¸)
            os.path.join(current_dir, "tag_recommendation_model.pkl"),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
            os.path.join(current_dir, "tags", "tag_recommendation_model.pkl"),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬/tags
            "tag_recommendation_model.pkl",  # ìƒëŒ€ ê²½ë¡œ
        ]
        
        print(f"ğŸ” íƒœê·¸ ì¶”ì²œ ëª¨ë¸ íŒŒì¼ ê²€ìƒ‰ ì‹œì‘...")
        print(f"   script_dir: {script_dir}")
        print(f"   project_root: {project_root}")
        print(f"   current_dir: {current_dir}")
        
        model_path = None
        for path in possible_paths:
            abs_path = os.path.abspath(path) if not os.path.isabs(path) else path
            print(f"   ì‹œë„: {abs_path} (ì¡´ì¬: {os.path.exists(abs_path)})")
            if os.path.exists(abs_path):
                model_path = abs_path
                print(f"   âœ… ëª¨ë¸ íŒŒì¼ ë°œê²¬: {abs_path}")
                break
        
        if model_path:
            print(f"ğŸ“¦ íƒœê·¸ ì¶”ì²œ ëª¨ë¸ ë¡œë”© ì‹œì‘: {model_path}")
            tag_model = TagRecommendationModel()
            tag_model.load_model(model_path)
            print(f"âœ… íƒœê·¸ ì¶”ì²œ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        else:
            print("âš ï¸ íƒœê·¸ ì¶”ì²œ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"   ì‹œë„í•œ ê²½ë¡œë“¤:")
            for path in possible_paths:
                abs_path = os.path.abspath(path) if not os.path.isabs(path) else path
                print(f"     - {abs_path}")
            print("   ğŸ’¡ Railway ë°°í¬ ì‹œ tags/tag_recommendation_model.pkl íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            tag_model = None
    except Exception as e:
        print(f"âŒ íƒœê·¸ ì¶”ì²œ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        print(f"âŒ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        tag_model = None

def get_current_user(session_token: str = None):
    """í˜„ì¬ ì‚¬ìš©ì ì¸ì¦"""
    if not session_token:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤."
        )
    
    user = user_db.validate_session(session_token)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ì…ë‹ˆë‹¤."
        )
    return user

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰"""
    # ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ ì‹œë„
    try:
        import subprocess
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        download_script = os.path.join(project_root, "download_models.py")
        
        # ëª¨ë¸ ë””ë ‰í† ë¦¬ì™€ íƒœê·¸ ëª¨ë¸ íŒŒì¼ í™•ì¸
        model_dir = os.path.join(project_root, "ëª¨ë¸")
        tag_model_path = os.path.join(script_dir, "tag_recommendation_model.pkl")
        
        # ëª¨ë¸ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ì‹œë„
        models_exist = (
            os.path.exists(model_dir) and 
            len([f for f in os.listdir(model_dir) if f.endswith(('.pkl', '.cbm'))]) > 0
        ) or os.path.exists(tag_model_path)
        
        if not models_exist and os.path.exists(download_script):
            print("ğŸ“¥ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
            try:
                result = subprocess.run(
                    [sys.executable, download_script],
                    capture_output=True,
                    text=True,
                    timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
                )
                if result.returncode == 0:
                    print("âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                else:
                    print(f"âš ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
            except Exception as e:
                print(f"âš ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    load_tag_model()

@app.get("/", response_class=HTMLResponse)
async def root():
    """ë©”ì¸ í˜ì´ì§€"""
    return """
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>1ë“± ìœ íŠœë²„ ë˜ê¸° API</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }
            .container { max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
            h1 { color: #e74c3c; text-align: center; }
            .api-list { margin: 20px 0; }
            .api-item { background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; border-left: 4px solid #e74c3c; }
            .method { font-weight: bold; color: #e74c3c; }
            .endpoint { font-family: monospace; background: #e9ecef; padding: 2px 6px; border-radius: 3px; }
            .description { margin-top: 5px; color: #666; }
            .docs-link { text-align: center; margin: 20px 0; }
            .docs-link a { background: #e74c3c; color: white; padding: 10px 20px; text-decoration: none; border-radius: 5px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ¬ 1ë“± ìœ íŠœë²„ ë˜ê¸° API</h1>
            <p style="text-align: center; color: #666;">ì‚¬ìš©ì ì¸ì¦ ë° íƒœê·¸ ì¶”ì²œ API ì„œë²„</p>
            
            <div class="docs-link">
                <a href="/docs" target="_blank">ğŸ“š API ë¬¸ì„œ ë³´ê¸° (Swagger UI)</a>
                <a href="/redoc" target="_blank" style="margin-left: 10px;">ğŸ“– API ë¬¸ì„œ ë³´ê¸° (ReDoc)</a>
            </div>
            
            <div class="api-list">
                <h2>ğŸ“‹ ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸</h2>
                
                <div class="api-item">
                    <div><span class="method">POST</span> <span class="endpoint">/api/auth/register</span></div>
                    <div class="description">ìƒˆ ì‚¬ìš©ì íšŒì›ê°€ì…</div>
                </div>
                
                <div class="api-item">
                    <div><span class="method">POST</span> <span class="endpoint">/api/auth/login</span></div>
                    <div class="description">ì‚¬ìš©ì ë¡œê·¸ì¸</div>
                </div>
                
                <div class="api-item">
                    <div><span class="method">POST</span> <span class="endpoint">/api/tags/recommend</span></div>
                    <div class="description">ì œëª© ê¸°ë°˜ íƒœê·¸ ì¶”ì²œ</div>
                </div>
                
                <div class="api-item">
                    <div><span class="method">POST</span> <span class="endpoint">/api/tags/refine</span></div>
                    <div class="description">í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ íƒœê·¸ ìˆ˜ì •</div>
                </div>
            </div>
            
            <div style="margin-top: 30px; padding: 20px; background: #e8f5e8; border-radius: 5px;">
                <h3>ğŸš€ ì„œë²„ ìƒíƒœ</h3>
                <p>âœ… FastAPI ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.</p>
                <p>ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤: SQLite</p>
                <p>ğŸ”— CORS: í™œì„±í™”</p>
                <p>ğŸ“š OpenAPI: ì§€ì›</p>
            </div>
        </div>
    </body>
    </html>
    """

# ì¸ì¦ API
@app.post("/api/auth/register", response_model=APIResponse)
async def register(user_data: UserRegister):
    """ì‚¬ìš©ì íšŒì›ê°€ì…"""
    try:
        # ì´ë©”ì¼ í˜•ì‹ ê²€ì¦
        email = user_data.email.strip().lower()
        if '@' not in email or '.' not in email:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ì˜¬ë°”ë¥¸ ì´ë©”ì¼ í˜•ì‹ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
            )
        
        # ì‚¬ìš©ì ìƒì„±
        user = user_db.create_user(
            email=email,
            password=user_data.password,
            name=user_data.name.strip(),
            role=user_data.role,
            profile_data=user_data.profile_data
        )
        
        # í™œë™ ë¡œê·¸ ê¸°ë¡
        user_db.log_user_activity(
            user_id=user['id'],
            activity_type='register',
            activity_data={'email': email, 'role': user_data.role},
            ip_address="127.0.0.1",  # FastAPIì—ì„œëŠ” request.remote_addr ëŒ€ì‹ 
            user_agent="FastAPI Client"
        )
        
        return UTF8JSONResponse(
            content={
                "success": True,
                "message": "íšŒì›ê°€ì…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "data": {"user": user}
            }
        )
        
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@app.post("/api/auth/login", response_model=APIResponse)
async def login(login_data: UserLogin):
    """ì‚¬ìš©ì ë¡œê·¸ì¸"""
    try:
        # ì‚¬ìš©ì ì¸ì¦
        user = user_db.authenticate_user(
            email=login_data.email.strip().lower(),
            password=login_data.password
        )
        
        if not user:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )
        
        # ì„¸ì…˜ ìƒì„±
        session_token = user_db.create_session(user['id'])
        
        # í™œë™ ë¡œê·¸ ê¸°ë¡
        user_db.log_user_activity(
            user_id=user['id'],
            activity_type='login',
            activity_data={'email': login_data.email},
            ip_address="127.0.0.1",
            user_agent="FastAPI Client"
        )
        
        return UTF8JSONResponse(
            content={
                "success": True,
                "message": "ë¡œê·¸ì¸ì— ì„±ê³µí–ˆìŠµë‹ˆë‹¤.",
                "data": {
                    "user": user,
                    "session_token": session_token
                }
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@app.post("/api/auth/logout", response_model=APIResponse)
async def logout(logout_data: UserLogout):
    """ì‚¬ìš©ì ë¡œê·¸ì•„ì›ƒ"""
    try:
        # ì„¸ì…˜ ê²€ì¦
        user = user_db.validate_session(logout_data.session_token)
        if not user:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì„¸ì…˜ì…ë‹ˆë‹¤."
            )
        
        # ì„¸ì…˜ ë¡œê·¸ì•„ì›ƒ
        user_db.logout_session(logout_data.session_token)
        
        # í™œë™ ë¡œê·¸ ê¸°ë¡
        user_db.log_user_activity(
            user_id=user['id'],
            activity_type='logout',
            ip_address="127.0.0.1",
            user_agent="FastAPI Client"
        )
        
        return UTF8JSONResponse(
            content={
                "success": True,
                "message": "ë¡œê·¸ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@app.get("/api/auth/profile", response_model=APIResponse)
async def get_profile(session_token: str = None):
    """ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ"""
    try:
        user = get_current_user(session_token)
        return UTF8JSONResponse(
            content={
                "success": True,
                "data": {"user": user}
            }
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@app.put("/api/auth/profile", response_model=APIResponse)
async def update_profile(profile_data: ProfileUpdate, session_token: str = None):
    """ì‚¬ìš©ì í”„ë¡œí•„ ì—…ë°ì´íŠ¸"""
    try:
        user = get_current_user(session_token)
        
        # í”„ë¡œí•„ ì—…ë°ì´íŠ¸
        success = user_db.update_user_profile(user['id'], profile_data.profile_data)
        
        if not success:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="í”„ë¡œí•„ ì—…ë°ì´íŠ¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            )
        
        # í™œë™ ë¡œê·¸ ê¸°ë¡
        user_db.log_user_activity(
            user_id=user['id'],
            activity_type='profile_update',
            activity_data={'updated_fields': list(profile_data.profile_data.keys())},
            ip_address="127.0.0.1",
            user_agent="FastAPI Client"
        )
        
        return UTF8JSONResponse(
            content={
                "success": True,
                "message": "í”„ë¡œí•„ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@app.get("/api/stats", response_model=APIResponse)
async def get_stats():
    """ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ"""
    try:
        stats = user_db.get_user_statistics()
        return UTF8JSONResponse(
            content={
                "success": True,
                "data": {"stats": stats}
            }
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

# íƒœê·¸ ì¶”ì²œ API
@app.post("/api/tags/recommend", response_model=TagRecommendResponse)
async def recommend_tags(request: TagRecommendRequest):
    """ì œëª© ê¸°ë°˜ íƒœê·¸ ì¶”ì²œ"""
    try:
        if tag_model is None:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="íƒœê·¸ ì¶”ì²œ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        title = request.title.strip()
        top_k = request.top_k
        method = request.method
        
        # íƒœê·¸ ì¶”ì²œ
        if method == "sbert":
            # SBERT ì§ì ‘ ì¶”ì²œ
            recommended_tags = tag_model.recommend_tags_with_sbert(title, top_k=top_k)
            result_tags = [item['tag'] for item in recommended_tags]
        elif method == "similarity":
            # ìœ ì‚¬í•œ ì œëª© ê¸°ë°˜ ì¶”ì²œ
            recommended_tags = tag_model.recommend_tags(title, top_k=top_k)
            result_tags = recommended_tags
        else:  # hybrid
            # ë‘ ë°©ë²•ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ
            sbert_tags = tag_model.recommend_tags_with_sbert(title, top_k=top_k//2)
            similarity_tags = tag_model.recommend_tags(title, top_k=top_k//2)
            
            # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ê²°í•©
            all_tags = []
            for item in sbert_tags:
                all_tags.append(item['tag'])
            for tag in similarity_tags:
                if tag not in all_tags:
                    all_tags.append(tag)
            
            result_tags = all_tags[:top_k]
        
        # ìœ ì‚¬í•œ ì œëª©ë“¤ë„ í•¨ê»˜ ë°˜í™˜ (ì°¸ê³ ìš©)
        similar_titles = tag_model.find_similar_titles(title, top_k=3)
        
        return TagRecommendResponse(
            success=True,
            title=title,
            recommended_tags=result_tags,
            method=method,
            similar_titles=similar_titles
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íƒœê·¸ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.post("/api/tags/refine", response_model=TagRefineResponse)
async def refine_tags(request: TagRefineRequest):
    """í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ íƒœê·¸ ìˆ˜ì •"""
    try:
        if tag_model is None:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="íƒœê·¸ ì¶”ì²œ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        title = request.title.strip()
        candidate_tags = request.candidate_tags or []
        
        # í›„ë³´ íƒœê·¸ê°€ ì—†ìœ¼ë©´ ë¨¼ì € ì¶”ì²œ
        if not candidate_tags:
            recommended_tags = tag_model.recommend_tags(title, top_k=15)
            candidate_tags = recommended_tags
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
ì•„ë˜ëŠ” ìœ íŠœë¸Œ ì˜ìƒ ì œëª©ê³¼ SBERTê°€ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œí•œ íƒœê·¸ í›„ë³´ì…ë‹ˆë‹¤.
ì œëª©: {title}
í›„ë³´ íƒœê·¸: {', '.join(candidate_tags)}

ìœ„ ì œëª©ì˜ ë¬¸ë§¥ê³¼ ì˜ë¯¸ì— ì–´ìš¸ë¦¬ë„ë¡ íƒœê·¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ìˆ˜ì •í•˜ê±°ë‚˜ ë³´ì™„í•´ì¤˜.
ë¶ˆí•„ìš”í•˜ê±°ë‚˜ ì œëª©ê³¼ ê´€ë ¨ ì—†ëŠ” ê±´ ì œê±°í•˜ê³ , ê´€ë ¨ ìˆëŠ” í‘œí˜„ì€ ìƒˆë¡œ ì¶”ê°€í•´ë„ ì¢‹ì•„.
ìµœì¢… ê²°ê³¼ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í˜•íƒœë¡œ ì‘ì„±í•´ì¤˜.
"""
        
        # ê°„ë‹¨í•œ í›„ì²˜ë¦¬ë¡œ íƒœê·¸ ìˆ˜ì •
        refined_tags = refine_tags_simple(title, candidate_tags)
        
        return TagRefineResponse(
            success=True,
            title=title,
            original_candidate_tags=candidate_tags,
            refined_tags=refined_tags,
            prompt=prompt
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íƒœê·¸ ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

def refine_tags_simple(title: str, candidate_tags: List[str]) -> List[str]:
    """ê°„ë‹¨í•œ íƒœê·¸ ìˆ˜ì • ë¡œì§ (ì‹¤ì œ LLM ëŒ€ì‹  ì‚¬ìš©)"""
    # ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    title_keywords = []
    title_lower = title.lower()
    
    # ë¸Œì´ë¡œê·¸ ê´€ë ¨ í‚¤ì›Œë“œ
    if any(keyword in title_lower for keyword in ['ë¸Œì´ë¡œê·¸', 'vlog', 'ì¼ìƒ']):
        title_keywords.extend(['ë¸Œì´ë¡œê·¸', 'vlog', 'ì¼ìƒ'])
    
    # ë¨¹ë°© ê´€ë ¨ í‚¤ì›Œë“œ
    if any(keyword in title_lower for keyword in ['ë¨¹ë°©', 'ë¨¹', 'ìŒì‹', 'ìš”ë¦¬']):
        title_keywords.extend(['ë¨¹ë°©', 'ë¨¹ë°©ë¸Œì´ë¡œê·¸', 'ìŒì‹'])
    
    # ì—¬í–‰ ê´€ë ¨ í‚¤ì›Œë“œ
    if any(keyword in title_lower for keyword in ['ì—¬í–‰', 'ì—¬í–‰ë¸Œì´ë¡œê·¸', 'ì—¬í–‰vlog']):
        title_keywords.extend(['ì—¬í–‰', 'ì—¬í–‰ë¸Œì´ë¡œê·¸', 'travel'])
    
    # ë©”ì´í¬ì—… ê´€ë ¨ í‚¤ì›Œë“œ
    if any(keyword in title_lower for keyword in ['ë©”ì´í¬ì—…', 'í™”ì¥', 'grwm']):
        title_keywords.extend(['ë©”ì´í¬ì—…', 'grwm', 'í™”ì¥'])
    
    # ë‹¤ì´ì–´íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œ
    if any(keyword in title_lower for keyword in ['ë‹¤ì´ì–´íŠ¸', 'ë‹¤ì´ì–´íŠ¸ë¸Œì´ë¡œê·¸', 'ê¸‰ì°ê¸‰ë¹ ']):
        title_keywords.extend(['ë‹¤ì´ì–´íŠ¸', 'ë‹¤ì´ì–´íŠ¸ë¸Œì´ë¡œê·¸', 'ë‹¤ì´ì–´íŠ¸vlog'])
    
    # ê¸°ì¡´ í›„ë³´ íƒœê·¸ì™€ ì œëª© í‚¤ì›Œë“œ ê²°í•©
    refined_tags = list(set(candidate_tags + title_keywords))
    
    # ê´€ë ¨ì„± ë‚®ì€ íƒœê·¸ ì œê±° (ê°„ë‹¨í•œ í•„í„°ë§)
    filtered_tags = []
    for tag in refined_tags:
        if len(tag) > 1 and not any(char.isdigit() for char in tag):
            filtered_tags.append(tag)
    
    return filtered_tags[:15]  # ìµœëŒ€ 15ê°œë¡œ ì œí•œ

@app.post("/api/tags/enrich", response_model=TagEnrichResponse)
async def enrich_tags(request: TagEnrichRequest):
    """ì œëª© ê¸°ë°˜ íƒœê·¸ ì¶”ì²œ ë° OpenAI ë³´ì • (enrich_tags.py ê¸°ëŠ¥)"""
    try:
        if tag_model is None:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="íƒœê·¸ ì¶”ì²œ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        title = request.title.strip()
        description = request.description.strip() if request.description else ""
        
        if not title:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="ì œëª©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."
            )
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì • (ì—¬ëŸ¬ ê²½ë¡œ ì‹œë„) - load_tag_modelê³¼ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(script_dir)
        current_dir = os.getcwd()
        
        possible_paths = [
            os.path.join(script_dir, "tag_recommendation_model.pkl"),  # tags/tag_recommendation_model.pkl
            os.path.join(project_root, "tags", "tag_recommendation_model.pkl"),  # í”„ë¡œì íŠ¸ ë£¨íŠ¸/tags/tag_recommendation_model.pkl
            "/app/tags/tag_recommendation_model.pkl",  # Railway ë°°í¬ í™˜ê²½ (tags ë””ë ‰í† ë¦¬)
            "/app/tag_recommendation_model.pkl",  # Railway ë°°í¬ í™˜ê²½ (ë£¨íŠ¸)
            os.path.join(current_dir, "tag_recommendation_model.pkl"),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬
            os.path.join(current_dir, "tags", "tag_recommendation_model.pkl"),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬/tags
            "tag_recommendation_model.pkl",  # ìƒëŒ€ ê²½ë¡œ
        ]
        
        model_path = None
        for path in possible_paths:
            abs_path = os.path.abspath(path) if not os.path.isabs(path) else path
            if os.path.exists(abs_path):
                model_path = abs_path
                print(f"âœ… enrich_tags ëª¨ë¸ íŒŒì¼ ë°œê²¬: {model_path}")
                break
        
        if not model_path:
            error_detail = f"íƒœê·¸ ì¶”ì²œ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nì‹œë„í•œ ê²½ë¡œ:\n"
            for path in possible_paths:
                abs_path = os.path.abspath(path) if not os.path.isabs(path) else path
                error_detail += f"  - {abs_path}\n"
            error_detail += "\nRailway ë°°í¬ ì‹œ tags/tag_recommendation_model.pkl íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail=error_detail
            )
        
        # enrich_tags íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì œëª©ê³¼ ì„¤ëª… ëª¨ë‘ ì‚¬ìš©)
        result = run_pipeline(
            model_path=model_path,
            title=title,
            description=description,
            top_k=request.top_k,
            title_sim_threshold=request.title_sim_threshold,
            tag_abs_threshold=request.tag_abs_threshold,
            extra_k=request.extra_k,
            api_key=request.api_key or os.environ.get("OPENAI_API_KEY")
        )
        
        # ì‘ë‹µ í˜•ì‹ ë³€í™˜
        scored_list = [{"tag": tag, "score": score} for tag, score in result["scored"]]
        
        return TagEnrichResponse(
            success=True,
            title=result["title"],
            description=result["description"],
            candidates=result["candidates"],
            scored=scored_list,
            kept=result["kept"],
            dropped=result["dropped"],
            final_tags=result["openai_result"].get("final_tags", []),
            extra_tags=result["openai_result"].get("extra_tags", [])
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íƒœê·¸ ì¶”ì²œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.post("/api/titles/generate", response_model=TitleGenerateResponse)
async def generate_titles(request: TitleGenerateRequest):
    """ì œëª© ì¶”ì²œ ê¸°ëŠ¥ (OpenAI GPT ì‚¬ìš©)"""
    try:
        # OpenAI API í‚¤ í™•ì¸
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (proxies ê´€ë ¨ ì—ëŸ¬ ë°©ì§€)
        # httpx í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§ì ‘ ì„¤ì •í•˜ì—¬ proxies ë¬¸ì œ íšŒí”¼
        try:
            import httpx
            http_client = httpx.Client(
                timeout=60.0,  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
                follow_redirects=True
            )
            client = OpenAI(
                api_key=api_key,
                http_client=http_client,
                max_retries=2
            )
        except Exception as e:
            # httpx í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì´ˆê¸°í™”
            print(f"âš ï¸ httpx í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨, ê¸°ë³¸ ì´ˆê¸°í™” ì‚¬ìš©: {e}")
            client = OpenAI(api_key=api_key)
        
        prompt = f"""
            ì‚¬ìš©ìê°€ '{request.keyword}'ë¼ëŠ” ì£¼ì œë¥¼ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.
            {f'ì´ë¯¸ì§€ì— í¬í•¨ëœ ë‚´ìš© ìš”ì•½: {request.imageText}' if request.imageText else ''}

            ì•„ë˜ ìœ íŠœë¸Œ ì œëª© ì‘ì„± ì „ëµì„ ì°¸ê³ í•˜ì—¬, ì‹¤ì œ ìœ íŠœë¸Œì—ì„œ í´ë¦­ì„ ìœ ë„í•  ìˆ˜ ìˆëŠ” í¥ë¯¸ë¡­ê³  ìê·¹ì ì¸ ì œëª© {request.n}ê°œë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.
            
            ìœ íŠœë¸Œ ì œëª© ìµœì í™” ì „ëµ (Actionable Tips):
            1. [í•„ìˆ˜] ì¼ì¹˜ì„± ë° ì‹ ë¢°: ì œëª©ì€ ì½˜í…ì¸  ë‚´ìš©ì„ ì •í™•íˆ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤ (í´ë¦­ë² ì´íŠ¸ ê¸ˆì§€).
            2. [ê²€ìƒ‰/SEO] í‚¤ì›Œë“œ: ì œëª© ì•ë¶€ë¶„ì— ì£¼ìš” í‚¤ì›Œë“œë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜í•©ë‹ˆë‹¤ (60ì ë¯¸ë§Œ ê¶Œì¥).
            3. [í´ë¦­ë¥ ] ê°€ì¹˜/ì§ˆë¬¸/ê¸´ë°•ê°: ì‹œì²­ìì˜ ë¬¸ì œ(ì§ˆë¬¸)ë¥¼ ì œê¸°í•˜ê±°ë‚˜, ëª…í™•í•œ ê°€ì¹˜("10ë¶„ ë§Œì— ì „ë¬¸ê°€ ë˜ê¸°")ë‚˜ ê¸´ë°•ê°("ë†“ì¹˜ì§€ ë§ˆì„¸ìš”")ì„ ì œì‹œí•©ë‹ˆë‹¤.
            4. [í˜•ì‹] ìˆ«ì/ê´„í˜¸: í™€ìˆ˜(7, 9)ë¥¼ í¬í•¨í•œ ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ì œëª©ê³¼ ê´„í˜¸ () ì‚¬ìš©ì€ í´ë¦­ë¥ ì„ ë†’ì…ë‹ˆë‹¤.
            5. [íƒ€ê¹ƒ] ì–¸ì–´: ì‹œì²­ìì˜ ì€ì–´/ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ê³  ì‹œì²­ì("ë‹¹ì‹ ")ì—ê²Œ ì§ì ‘ ëª…ë ¹í•©ë‹ˆë‹¤.
            6. [ì‹œë„ˆì§€] ì¸ë„¤ì¼: ì œëª©ì€ ì¸ë„¤ì¼ê³¼ ì¼ê´€ì„± ìˆê²Œ ì¡°í™”ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
            7. [ê²½ìŸ] ë¶„ì„: ê²½ìŸì‚¬ ìƒìœ„ ë™ì˜ìƒì˜ ì œëª© êµ¬ì¡°ë¥¼ ì—°êµ¬í•˜ì—¬ ë³€í˜•í•©ë‹ˆë‹¤.
            8. [ì¶”ê°€] ì™€ìš° ìš”ì†Œ: 'ë†€ë¼ìš´', 'ì¶©ê²©ì ì¸', 'ì—­ëŒ€ê¸‰' ë“±ì˜ ê°íƒ„ì‚¬/ìˆ˜ì‹ì–´ë¥¼ í™œìš©í•˜ì—¬ í˜¸ê¸°ì‹¬ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
            9. [êµìœ¡/ë¦¬ìŠ¤íŠ¸] 'í•˜ìš°íˆ¬(How-to)' ë˜ëŠ” 'ë¦¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼' í˜•ì‹ì„ ì ìš©í•©ë‹ˆë‹¤.

            ì œëª©ì€ ìì—°ìŠ¤ëŸ½ê³  ìœ ë¨¸/ê°íƒ„ì‚¬/ì˜ë¬¸í˜• ë“±ì„ ì ì ˆíˆ í™œìš©í•˜ì—¬ ì‚¬ëŒë“¤ì˜ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ì„¸ìš”.
            ì œëª© ëª©ë¡ë§Œ ì¶œë ¥í•´ ì£¼ì„¸ìš”. (ì˜ˆ: 1. ... 2. ...)
            """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=1.0,
        )
        
        content = response.choices[0].message.content.strip()
        
        # ì œëª© ëª©ë¡ íŒŒì‹± (1. 2. 3. í˜•ì‹ ë˜ëŠ” - í˜•ì‹)
        titles = []
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
            # ìˆ«ìë‚˜ ê¸°í˜¸ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš° ì œê±° (ì •ê·œì‹ ì‚¬ìš©)
            line = re.sub(r'^\d+[\.\)]\s*', '', line)  # "1. " ë˜ëŠ” "1) " ì œê±°
            line = re.sub(r'^[-â€¢]\s*', '', line)  # "- " ë˜ëŠ” "â€¢ " ì œê±°
            line = line.strip()
            if line and len(line) > 0:
                titles.append(line)
        
        # ìš”ì²­í•œ ê°œìˆ˜ë§Œí¼ë§Œ ë°˜í™˜
        titles = titles[:request.n]
        
        if not titles:
            return TitleGenerateResponse(
                success=False,
                titles=[],
                message="ì œëª© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            )
        
        return TitleGenerateResponse(
            success=True,
            titles=titles,
            message=None
        )
        
    except HTTPException:
        raise
    except Exception as e:
        error_msg = str(e)
        error_detail = ""
        
        # OpenAI API ê´€ë ¨ ì—ëŸ¬ ë©”ì‹œì§€ ê°œì„ 
        if "401" in error_msg or "invalid_api_key" in error_msg.lower() or "incorrect api key" in error_msg.lower():
            error_detail = "OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Railway í™˜ê²½ ë³€ìˆ˜ì—ì„œ OPENAI_API_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            status_code = status.HTTP_503_SERVICE_UNAVAILABLE
        elif "timeout" in error_msg.lower() or "timed out" in error_msg.lower():
            error_detail = "OpenAI API ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            status_code = status.HTTP_504_GATEWAY_TIMEOUT
        elif "rate limit" in error_msg.lower():
            error_detail = "OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            status_code = status.HTTP_429_TOO_MANY_REQUESTS
        elif "authentication" in error_msg.lower():
            error_detail = "OpenAI API ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            status_code = status.HTTP_503_SERVICE_UNAVAILABLE
        else:
            error_detail = f"ì œëª© ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}"
            status_code = status.HTTP_500_INTERNAL_SERVER_ERROR
        
        raise HTTPException(
            status_code=status_code,
            detail=error_detail
        )

@app.post("/api/videos/create", response_model=VideoResponse)
async def create_video(
    request: VideoCreateRequest,
    session_token: Optional[str] = Query(None, description="ì„¸ì…˜ í† í°")
):
    """ì˜ìƒ ì •ë³´ ì €ì¥ ë° ì¡°íšŒìˆ˜ ì˜ˆì¸¡"""
    print(f"ğŸš€ /api/videos/create ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œë¨")
    print(f"ğŸš€ ìš”ì²­ ë°ì´í„°: {request}")
    print(f"ğŸš€ ì„¸ì…˜ í† í°: {session_token}")
    
    try:
        # ì‚¬ìš©ì ID ì¶”ì¶œ (ë¡œê·¸ì¸í•œ ê²½ìš°)
        user_id = None
        if session_token:
            try:
                validated_user = user_db.validate_session(session_token)
                if validated_user:
                    user_id = validated_user['id']
                    print(f"ğŸš€ ì‚¬ìš©ì ID: {user_id}")
                else:
                    print(f"ğŸš€ ì„¸ì…˜ í† í°ì´ ìœ íš¨í•˜ì§€ ì•ŠìŒ")
            except Exception as e:
                print(f"âš ï¸ ì„¸ì…˜ í† í° ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
        else:
            print(f"ğŸš€ ì„¸ì…˜ í† í°ì´ ì—†ìŒ (ë¹„ë¡œê·¸ì¸ ìƒíƒœ)")
        
        print(f"ğŸš€ create_video í•¨ìˆ˜ í˜¸ì¶œ ì „")
        print(f"ğŸš€ ì €ì¥í•  ë°ì´í„°: title={request.title}, category={request.category}, length={request.length}")
        
        # ì¡°íšŒìˆ˜ ì˜ˆì¸¡ ìˆ˜í–‰
        print("\n" + "!" * 80)
        print("!" * 80)
        print("ğŸš€ [ì¡°íšŒìˆ˜ ì˜ˆì¸¡ ìˆ˜í–‰ ì‹œì‘ - ì½”ë“œ ì‹¤í–‰ í™•ì¸]")
        print("!" * 80)
        print("!" * 80 + "\n")
        
        prediction_result = None
        print("\n" + "=" * 80)
        print("ğŸš€ [ì¡°íšŒìˆ˜ ì˜ˆì¸¡ ì‹œì‘]")
        print("=" * 80)
        print(f"ğŸ” ì˜ˆì¸¡ ì‹œì‘ - ì¹´í…Œê³ ë¦¬: {request.category}")
        try:
            # ë°ì´í„° ì „ì²˜ë¦¬
            print(f"\nğŸ“Š [1ë‹¨ê³„] ì „ì²˜ë¦¬ ì‹œì‘...")
            input_df = preprocess_input_data(request)
            print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ!")
            print(f"ğŸ“Š ì…ë ¥ ë°ì´í„° shape: {input_df.shape}")
            print(f"ğŸ“Š ì…ë ¥ ë°ì´í„° columns: {input_df.columns.tolist()}")
            print(f"\nğŸ“Š ì „ì²˜ë¦¬ëœ ì…ë ¥ ë°ì´í„°:")
            print(input_df)
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            print(f"\nğŸ” [2ë‹¨ê³„] predict_views í˜¸ì¶œ ì‹œì‘, category: {request.category}")
            prediction_result = predict_views(request.category, input_df)
            print(f"\n" + "=" * 80)
            print("âœ… [ì¡°íšŒìˆ˜ ì˜ˆì¸¡ ì™„ë£Œ]")
            print("=" * 80)
            print(f"âœ… ì¡°íšŒìˆ˜ ì˜ˆì¸¡ ê²°ê³¼: {prediction_result}")
            print("=" * 80 + "\n")
        except HTTPException as pred_error:
            # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ (ìƒíƒœ ì½”ë“œì™€ í•¨ê»˜)
            print(f"âš ï¸ ì¡°íšŒìˆ˜ ì˜ˆì¸¡ ì‹¤íŒ¨ (HTTPException): {str(pred_error)}")
            print(f"âš ï¸ ìƒíƒœ ì½”ë“œ: {pred_error.status_code}")
            print(f"âš ï¸ ìƒì„¸ ë©”ì‹œì§€: {pred_error.detail}")
            # HTTPExceptionì€ ìƒìœ„ë¡œ ì „íŒŒë˜ì–´ì•¼ í•¨
            raise
        except Exception as pred_error:
            print(f"âš ï¸ ì¡°íšŒìˆ˜ ì˜ˆì¸¡ ì‹¤íŒ¨: {str(pred_error)}")
            import traceback
            print(f"âš ï¸ ì˜ˆì¸¡ ì‹¤íŒ¨ ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
            # ì˜ˆì¸¡ ì‹¤íŒ¨í•´ë„ ì €ì¥ì€ ê³„ì† ì§„í–‰ (prediction_resultëŠ” Noneìœ¼ë¡œ ìœ ì§€)
        
        # ì˜ìƒ ì •ë³´ ì €ì¥
        try:
            video = user_db.create_video(
                title=request.title,
                category=request.category,
                length=request.length,
                upload_time=request.upload_time,
                description=request.description,
                thumbnail_image=request.thumbnail_image,
                user_id=user_id
            )
            print(f"ğŸš€ create_video í•¨ìˆ˜ í˜¸ì¶œ ì™„ë£Œ: {video}")
        except Exception as db_error:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì˜¤ë¥˜: {str(db_error)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(db_error)}"
            )
        
        # predictionì´ Noneì´ì–´ë„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
        print("\n" + "=" * 80)
        print("ğŸ“¤ [ì‘ë‹µ ìƒì„±]")
        print("=" * 80)
        print(f"ğŸ“Š prediction_result ê°’: {prediction_result}")
        print(f"ğŸ“Š prediction_result íƒ€ì…: {type(prediction_result)}")
        print(f"ğŸ“Š prediction_result is None: {prediction_result is None}")
        
        data_dict = {
            "video": video
        }
        # Noneì´ì–´ë„ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
        data_dict["prediction"] = prediction_result
        
        print(f"ğŸ“Š data_dictì— prediction í¬í•¨ ì—¬ë¶€: {'prediction' in data_dict}")
        print(f"ğŸ“Š data_dict['prediction'] ê°’: {data_dict['prediction']}")
        
        response_data = {
            "success": True,
            "message": "ì˜ìƒ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "data": data_dict
        }
        
        print(f"ğŸ“Š response_data['data']ì— prediction í¬í•¨ ì—¬ë¶€: {'prediction' in response_data['data']}")
        print(f"ğŸ“Š response_data['data']['prediction'] ê°’: {response_data['data'].get('prediction')}")
        print(f"âœ… ìµœì¢… ì‘ë‹µ ë°ì´í„° êµ¬ì¡°:")
        print(f"   - success: {response_data['success']}")
        print(f"   - data.video: {response_data['data'].get('video') is not None}")
        print(f"   - data.prediction: {response_data['data'].get('prediction')}")
        print("=" * 80 + "\n")
        
        # JSONResponseë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ ì¸ì½”ë”© ë³´ì¥
        response = UTF8JSONResponse(content=response_data)
        print(f"ğŸ“Š ì‘ë‹µ ì§ë ¬í™” í›„ í™•ì¸: predictionì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ í•„ìš”")
        return response
        
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì¬ë°œìƒ
        raise
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        print(f"âŒ íŠ¸ë ˆì´ìŠ¤ë°±: {traceback.format_exc()}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì˜ìƒ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@app.get("/api/videos/list", response_model=APIResponse)
async def get_videos(session_token: str = None, limit: int = 100, offset: int = 0):
    """ì˜ìƒ ëª©ë¡ ì¡°íšŒ"""
    try:
        user_id = None
        if session_token:
            user = user_db.validate_session(session_token)
            if user:
                user_id = user['id']
        
        if user_id:
            # ë¡œê·¸ì¸í•œ ì‚¬ìš©ìì˜ ì˜ìƒ ëª©ë¡
            videos = user_db.get_user_videos(user_id)
        else:
            # ì „ì²´ ì˜ìƒ ëª©ë¡
            videos = user_db.get_all_videos(limit=limit, offset=offset)
        
        # ì‘ë‹µ ë°ì´í„° ì¤€ë¹„
        response_data = {
            "success": True,
            "message": "ì˜ìƒ ëª©ë¡ì„ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤.",
            "data": {
                "videos": videos,
                "count": len(videos)
            }
        }
        
        # JSONResponseë¥¼ ì‚¬ìš©í•˜ì—¬ í•œê¸€ ì¸ì½”ë”© ë³´ì¥
        return UTF8JSONResponse(content=response_data)
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì˜ìƒ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

class TrendUpdateResponse(BaseModel):
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None

@app.get("/api/trends/test-kaggle")
async def test_kaggle_download():
    """Kaggle ë°ì´í„° ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    try:
        # Kaggle API ì¸ì¦
        kaggle_username = os.environ.get('KAGGLE_USERNAME')
        kaggle_key = os.environ.get('KAGGLE_KEY')
        
        if not kaggle_username or not kaggle_key:
            return UTF8JSONResponse(content={
                "success": False,
                "message": "KAGGLE_USERNAME ë˜ëŠ” KAGGLE_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "data": None
            })
        
        print(f"ğŸ” Kaggle API ì¸ì¦ ì‹œë„...")
        os.environ['KAGGLE_USERNAME'] = kaggle_username
        os.environ['KAGGLE_KEY'] = kaggle_key
        
        # .kaggle í´ë”ì— íŒŒì¼ ìƒì„±
        import pathlib
        home_dir = pathlib.Path.home()
        kaggle_home_dir = home_dir / '.kaggle'
        kaggle_home_json = kaggle_home_dir / 'kaggle.json'
        
        if not kaggle_home_dir.exists():
            kaggle_home_dir.mkdir(parents=True, exist_ok=True)
        
        kaggle_creds = {'username': kaggle_username, 'key': kaggle_key}
        with open(str(kaggle_home_json), 'w') as f:
            json.dump(kaggle_creds, f)
        
        try:
            os.chmod(str(kaggle_home_json), 0o600)
        except:
            pass
        
        api = KaggleApi()
        api.authenticate()
        print(f"âœ… Kaggle API ì¸ì¦ ì„±ê³µ!")
        
        # ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸
        dataset = "asaniczka/trending-youtube-videos-113-countries"
        print(f"ğŸ“¥ Kaggle ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {dataset}")
        
        import tempfile
        import shutil
        
        temp_dir = tempfile.mkdtemp()
        print(f"   ğŸ“ ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±: {temp_dir}")
        try:
            print(f"   â³ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            api.dataset_download_files(dataset, path=temp_dir, unzip=True)
            print(f"   âœ… ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
            
            # ë””ë ‰í† ë¦¬ êµ¬ì¡° í™•ì¸
            print(f"   ğŸ“‚ ë‹¤ìš´ë¡œë“œëœ íŒŒì¼ ëª©ë¡:")
            for root, dirs, files in os.walk(temp_dir):
                level = root.replace(temp_dir, '').count(os.sep)
                indent = ' ' * 2 * level
                print(f"{indent}{os.path.basename(root)}/")
                subindent = ' ' * 2 * (level + 1)
                for file in files:
                    file_path = os.path.join(root, file)
                    file_size = os.path.getsize(file_path)
                    print(f"{subindent}{file} ({file_size:,} bytes)")
            
            # CSV íŒŒì¼ ì°¾ê¸°
            csv_files = []
            for root, dirs, files in os.walk(temp_dir):
                for file in files:
                    if file.endswith('.csv'):
                        file_path = os.path.join(root, file)
                        csv_files.append({
                            'path': file_path,
                            'name': file,
                            'size': os.path.getsize(file_path)
                        })
                        print(f"   âœ… CSV íŒŒì¼ ë°œê²¬: {file} ({os.path.getsize(file_path):,} bytes)")
            
            if not csv_files:
                return UTF8JSONResponse(content={
                    "success": False,
                    "message": "CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "data": {"temp_dir": temp_dir, "files": list(os.walk(temp_dir))}
                })
            
            # ì²« ë²ˆì§¸ CSV íŒŒì¼ ì½ê¸° (ìƒ˜í”Œ)
            csv_file = csv_files[0]['path']
            print(f"ğŸ“– CSV íŒŒì¼ ì½ê¸°: {csv_file}")
            df = pd.read_csv(csv_file, encoding='utf-8-sig', nrows=100)  # ì²˜ìŒ 100í–‰ë§Œ
            
            # ì»¬ëŸ¼ ì •ë³´ ìƒì„¸ ì¶œë ¥
            print(f"\n{'='*80}")
            print(f"ğŸ“Š CSV íŒŒì¼ ì»¬ëŸ¼ ì •ë³´")
            print(f"{'='*80}")
            print(f"   ì´ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
            print(f"   ì»¬ëŸ¼ ëª©ë¡:")
            for i, col in enumerate(df.columns, 1):
                print(f"      {i:2d}. {col}")
            print(f"\n   ì»¬ëŸ¼ íƒ€ì…:")
            for col in df.columns:
                dtype = df[col].dtype
                null_count = df[col].isna().sum()
                print(f"      {col:30s} : {str(dtype):15s} (null: {null_count}/{len(df)})")
            print(f"{'='*80}\n")
            
            # NaN ê°’ì„ Noneìœ¼ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
            df = df.replace({pd.NA: None, pd.NaT: None})
            df = df.where(pd.notnull(df), None)
            
            # ìƒ˜í”Œ ë°ì´í„° ì¤€ë¹„ (NaN ì²˜ë¦¬)
            sample_data = {
                "rows": len(df),
                "columns": list(df.columns),
                "first_row": None,
                "sample": []
            }
            
            if len(df) > 0:
                # ì²« ë²ˆì§¸ í–‰ (NaNì„ Noneìœ¼ë¡œ ë³€í™˜)
                first_row = df.iloc[0].to_dict()
                first_row = {k: (None if pd.isna(v) else v) for k, v in first_row.items()}
                sample_data["first_row"] = first_row
                
                # ìƒ˜í”Œ 5í–‰ (NaNì„ Noneìœ¼ë¡œ ë³€í™˜)
                sample_df = df.head(5).copy()
                sample_records = []
                for _, row in sample_df.iterrows():
                    record = {}
                    for col in sample_df.columns:
                        val = row[col]
                        if pd.isna(val):
                            record[col] = None
                        elif isinstance(val, (int, float)) and (pd.isna(val) or not np.isfinite(val)):
                            record[col] = None
                        else:
                            record[col] = val
                    sample_records.append(record)
                sample_data["sample"] = sample_records
            
            return UTF8JSONResponse(content={
                "success": True,
                "message": "Kaggle ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì„±ê³µ!",
                "data": {
                    "csv_files": csv_files,
                    "sample_data": sample_data
                }
            })
            
        finally:
            try:
                shutil.rmtree(temp_dir)
                print(f"ğŸ—‘ï¸ ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")
                
    except Exception as e:
        import traceback
        error_detail = f"Kaggle ë°ì´í„° ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}\n{traceback.format_exc()}"
        print(f"âŒ {error_detail}")
        return UTF8JSONResponse(content={
            "success": False,
            "message": error_detail,
            "data": None
        })

@app.post("/api/trends/update-month", response_model=TrendUpdateResponse)
async def update_trends_month(month: int = Query(..., ge=1, le=12, description="ì›” (1-12)")):
    """Kaggle APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì›”ì˜ íŠ¸ë Œë“œ ë¶„ì„ ì—…ë°ì´íŠ¸"""
    import tempfile
    import shutil
    import io
    import zipfile
    
    try:
        # Kaggle API ì¸ì¦ - í™˜ê²½ ë³€ìˆ˜ì—ì„œë§Œ ì½ê¸°
        kaggle_username = os.environ.get('KAGGLE_USERNAME')
        kaggle_key = os.environ.get('KAGGLE_KEY')
        
        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        if not kaggle_username or not kaggle_key:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="KAGGLE_USERNAME ë˜ëŠ” KAGGLE_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”."
            )
        
        print(f"ğŸ” Kaggle API ì¸ì¦ ì‹œë„...")
        print(f"   KAGGLE_USERNAME: {kaggle_username}")
        print(f"   KAGGLE_KEY: {'*' * len(kaggle_key)}")
        
        # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (í™•ì‹¤íˆ ì„¤ì •)
        os.environ['KAGGLE_USERNAME'] = kaggle_username
        os.environ['KAGGLE_KEY'] = kaggle_key
        
        # .kaggle í´ë”ì— íŒŒì¼ ìƒì„± (Kaggle APIê°€ íŒŒì¼ë„ í™•ì¸í•˜ë¯€ë¡œ)
        import pathlib
        home_dir = pathlib.Path.home()
        kaggle_home_dir = home_dir / '.kaggle'
        kaggle_home_json = kaggle_home_dir / 'kaggle.json'
        
        # .kaggle í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not kaggle_home_dir.exists():
            kaggle_home_dir.mkdir(parents=True, exist_ok=True)
            print(f"   ğŸ“ .kaggle í´ë” ìƒì„±: {kaggle_home_dir}")
        
        # kaggle.json íŒŒì¼ ìƒì„± (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì½ì€ ê°’ìœ¼ë¡œ)
        kaggle_creds = {
            'username': kaggle_username,
            'key': kaggle_key
        }
        with open(str(kaggle_home_json), 'w') as f:
            json.dump(kaggle_creds, f)
        print(f"   ğŸ“‹ kaggle.json íŒŒì¼ ìƒì„±: {kaggle_home_json}")
        
        # íŒŒì¼ ê¶Œí•œ ì„¤ì •
        try:
            os.chmod(str(kaggle_home_json), 0o600)
        except:
            pass
        
        # Kaggle API ì´ˆê¸°í™” ë° ì¸ì¦
        api = KaggleApi()
        
        try:
            api.authenticate()
            print(f"âœ… Kaggle API ì¸ì¦ ì„±ê³µ!")
        except Exception as auth_error:
            # ì¸ì¦ ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì •ë³´ ì¶œë ¥
            error_msg = str(auth_error)
            print(f"âŒ Kaggle API ì¸ì¦ ì‹¤íŒ¨:")
            print(f"   ì—ëŸ¬ ë©”ì‹œì§€: {error_msg}")
            print(f"   KAGGLE_USERNAME: {kaggle_username if kaggle_username else 'ì„¤ì • ì•ˆë¨'}")
            print(f"   KAGGLE_KEY: {'ì„¤ì •ë¨' if kaggle_key else 'ì„¤ì • ì•ˆë¨'}")
            print(f"   kaggle.json íŒŒì¼: {kaggle_home_json}")
            print(f"   íŒŒì¼ ì¡´ì¬: {os.path.exists(str(kaggle_home_json))}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Kaggle API ì¸ì¦ ì‹¤íŒ¨: {error_msg}. í™˜ê²½ ë³€ìˆ˜ KAGGLE_USERNAMEê³¼ KAGGLE_KEYë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        
        # ì „ì—­ ìºì‹œ í™•ì¸ ë° ë°ì´í„° ë¡œë“œ
        global df_2025_cache, cache_metadata
        
        if df_2025_cache is None:
            # ìºì‹œê°€ ì—†ìœ¼ë©´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ì²˜ë¦¬
            print(f"ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° 2025ë…„ ë°ì´í„° í•„í„°ë§ ì‹œì‘...")
            
            dataset = "asaniczka/trending-youtube-videos-113-countries"
            print(f"ğŸ“¥ Kaggle ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {dataset}")
            
            import tempfile
            import shutil
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            temp_dir = tempfile.mkdtemp()
            try:
                # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ë‹¤ìš´ë¡œë“œ
                api.dataset_download_files(dataset, path=temp_dir, unzip=True)
                
                # CSV íŒŒì¼ ì°¾ê¸°
                csv_file = None
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file.endswith('.csv') and 'trending' in file.lower():
                            csv_file = os.path.join(root, file)
                            break
                    if csv_file:
                        break
                
                if not csv_file or not os.path.exists(csv_file):
                    raise HTTPException(
                        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                        detail="CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    )
                
                # CSV íŒŒì¼ ì½ê¸° (ë©”ëª¨ë¦¬ë¡œ)
                print(f"ğŸ“– CSV íŒŒì¼ ì½ê¸°: {csv_file}")
                try:
                    df = pd.read_csv(csv_file, encoding='utf-8-sig')
                    print(f"   âœ… CSV íŒŒì¼ ì½ê¸° ì„±ê³µ: {len(df)}í–‰")
                except Exception as csv_error:
                    print(f"   âŒ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {csv_error}")
                    raise HTTPException(
                        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                        detail=f"CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(csv_error)}"
                    )
                
            finally:
                # ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ
                try:
                    shutil.rmtree(temp_dir)
                    print(f"ğŸ—‘ï¸ ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì™„ë£Œ: {temp_dir}")
                except Exception as e:
                    print(f"âš ï¸ ì„ì‹œ ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")
            
            # ë°ì´í„°í”„ë ˆì„ ìœ íš¨ì„± ê²€ì‚¬
            if df is None or df.empty:
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail="ë°ì´í„°í”„ë ˆì„ì´ ë¹„ì–´ìˆê±°ë‚˜ Noneì…ë‹ˆë‹¤."
                )
            
            # ë°ì´í„°í”„ë ˆì„ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…)
            print(f"ğŸ“Š ë°ì´í„°í”„ë ˆì„ ì •ë³´:")
            print(f"   í–‰ ìˆ˜: {len(df)}")
            print(f"   ì»¬ëŸ¼: {list(df.columns)}")
            print(f"   ì»¬ëŸ¼ íƒ€ì…: {type(df.columns)}")
            
            # 1. country ì»¬ëŸ¼ì—ì„œ KR, krì¸ ê²ƒë§Œ í•„í„°ë§
            if 'country' in df.columns:
                df = df[df['country'].str.upper().isin(['KR', 'KOREA'])]
                print(f"   âœ… KR ë°ì´í„° í•„í„°ë§ í›„ í–‰ ìˆ˜: {len(df)}")
            else:
                print(f"   âš ï¸ country ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  êµ­ê°€ ë°ì´í„° ì‚¬ìš©")
            
            # 2. published_at ë˜ëŠ” ë‹¤ë¥¸ ë‚ ì§œ ì»¬ëŸ¼ í™•ì¸
            date_column = None
            try:
                for col in ['published_at', 'publish_date', 'publishedAt', 'publishDate', 'published_date', 'trending_date', 'snapshot_date']:
                    if col in df.columns:
                        date_column = col
                        break
            except Exception as col_error:
                print(f"   âŒ ì»¬ëŸ¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {col_error}")
                print(f"   df íƒ€ì…: {type(df)}")
                print(f"   df.columns íƒ€ì…: {type(df.columns)}")
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail=f"ì»¬ëŸ¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(col_error)}"
                )
            
            if not date_column:
                available_cols = ', '.join(df.columns.tolist())
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail=f"ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {available_cols}"
                )
            
            print(f"   âœ… ë‚ ì§œ ì»¬ëŸ¼ ë°œê²¬: {date_column}")
            
            # ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
            df[date_column] = pd.to_datetime(df[date_column], errors='coerce')
            df = df.dropna(subset=[date_column])
            
            # 2025ë…„ ë°ì´í„°ë§Œ í•„í„°ë§
            df_2025 = df[df[date_column].dt.year == 2025]
            print(f"   âœ… 2025ë…„ ë°ì´í„° í–‰ ìˆ˜: {len(df_2025)}")
            
            # 3. video_id, title, published_date, viewsë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ ì‚­ì œ
            video_id_column = None
            for col in ['video_id', 'videoId', 'id']:
                if col in df_2025.columns:
                    video_id_column = col
                    break
            
            if not video_id_column:
                available_cols = ', '.join(df_2025.columns.tolist())
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail=f"video_id ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {available_cols}"
                )
            
            title_column = None
            for col in ['title', 'Title', 'video_title']:
                if col in df_2025.columns:
                    title_column = col
                    break
            
            if not title_column:
                available_cols = ', '.join(df_2025.columns.tolist())
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail=f"title ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {available_cols}"
                )
            
            views_column = None
            for col in ['views', 'view_count', 'viewCount', 'view_count_total']:
                if col in df_2025.columns:
                    views_column = col
                    break
            
            if not views_column:
                available_cols = ', '.join(df_2025.columns.tolist())
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail=f"views ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼: {available_cols}"
                )
            
            # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (video_id, title, published_date, views)
            df_2025 = df_2025[[video_id_column, title_column, date_column, views_column]].copy()
            # ì»¬ëŸ¼ëª…ì„ í‘œì¤€í™”
            df_2025.columns = ['video_id', 'title', 'published_date', 'views']
            print(f"   âœ… ì»¬ëŸ¼ ì •ë¦¬ ì™„ë£Œ: video_id, title, published_date, views (ì›ë˜ ì»¬ëŸ¼: {video_id_column}, {title_column}, {date_column}, {views_column})")
            
            # 4. YouTube APIë¥¼ ì‚¬ìš©í•´ì„œ category ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
            youtube_api_key = os.environ.get('YOUTUBE_API_KEY', 'AIzaSyC8lNQlD0nYRlophLuezpx1ihSbzQvGLv8')
            
            if not YOUTUBE_API_AVAILABLE:
                raise HTTPException(
                    status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                    detail="googleapiclient íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                )
            
            print(f"   ğŸ“º YouTube APIë¡œ ì¹´í…Œê³ ë¦¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹œì‘...")
            print(f"   ğŸ”‘ YouTube API í‚¤ ì‚¬ìš©: {youtube_api_key[:10]}...")
            youtube = build('youtube', 'v3', developerKey=youtube_api_key)
            
            # video_id ë¦¬ìŠ¤íŠ¸ë¥¼ 50ê°œì”© ë‚˜ëˆ„ì–´ ì²˜ë¦¬ (YouTube API ì œí•œ)
            video_ids = df_2025['video_id'].unique().tolist()
            categories = {}  # categoryë§Œ ê°€ì ¸ì˜¤ê¸°
            
            def chunks(lst, n):
                """ë¦¬ìŠ¤íŠ¸ë¥¼ nê°œì”© ë‚˜ëˆ„ê¸°"""
                for i in range(0, len(lst), n):
                    yield lst[i:i + n]
            
            import time
            for i, chunk in enumerate(chunks(video_ids, 50)):
                try:
                    videos_response = youtube.videos().list(
                        part='snippet',  # snippetë§Œ ê°€ì ¸ì˜¤ê¸° (categoryë§Œ í•„ìš”)
                        id=','.join(chunk)
                    ).execute()
                    
                    for item in videos_response.get('items', []):
                        video_id = item['id']
                        category_id = item['snippet'].get('categoryId', '')
                        categories[video_id] = category_id
                    
                    # API í˜¸ì¶œ ì œí•œ ëŒ€ë¹„ (ì´ˆë‹¹ 1íšŒ)
                    if i < len(list(chunks(video_ids, 50))) - 1:
                        time.sleep(1)
                    
                    if (i + 1) % 10 == 0:
                        print(f"      ì§„í–‰ ì¤‘: {min((i + 1) * 50, len(video_ids))}/{len(video_ids)}")
                        
                except Exception as e:
                    print(f"      âš ï¸ YouTube API í˜¸ì¶œ ì˜¤ë¥˜ (chunk {i+1}): {e}")
                    continue
            
            # category ì»¬ëŸ¼ë§Œ ì¶”ê°€ (viewsëŠ” CSVì—ì„œ ê°€ì ¸ì˜¨ ê²ƒ ì‚¬ìš©)
            df_2025['category'] = df_2025['video_id'].map(categories)
            df_2025 = df_2025.dropna(subset=['category'])  # categoryê°€ ì—†ëŠ” í–‰ ì œê±°
            print(f"   âœ… ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ê°€ ì™„ë£Œ: {len(df_2025)}ê°œ ì˜ìƒ")
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬
            category_column = 'category'
            views_column = 'views'
            video_id_column = 'video_id'
            date_column = 'published_date'  # ì»¬ëŸ¼ëª… í‘œì¤€í™”ë¨
            
            # ìµœì¢… ë°ì´í„°í”„ë ˆì„ í™•ì¸
            print(f"   ğŸ“Š ìµœì¢… ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼: {list(df_2025.columns)}")
            print(f"   ğŸ“Š ìµœì¢… ë°ì´í„°í”„ë ˆì„ í–‰ ìˆ˜: {len(df_2025)}")
            
            # ìºì‹œì— ì €ì¥
            df_2025_cache = df_2025.copy()
            cache_metadata = {
                'date_column': date_column,
                'category_column': category_column,
                'views_column': views_column,
                'video_id_column': video_id_column
            }
            print(f"   ğŸ’¾ 2025ë…„ ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ")
        else:
            print(f"   â™»ï¸ ìºì‹œëœ 2025ë…„ ë°ì´í„° ì‚¬ìš©")
        
        # ìºì‹œì—ì„œ ë°ì´í„° ë° ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        df_2025 = df_2025_cache.copy()
        date_column = cache_metadata['date_column']
        category_column = cache_metadata['category_column']
        views_column = cache_metadata['views_column']
        video_id_column = cache_metadata['video_id_column']
        
        print(f"   ğŸ“Š ìºì‹œì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„°: {len(df_2025)}í–‰, ì»¬ëŸ¼: {list(df_2025.columns)}")
        
        # íŠ¹ì • ì›”ì˜ íŠ¸ë Œë“œ ë¶„ì„
        print(f"ğŸ“… {month}ì›” ë°ì´í„° ë¶„ì„ ì‹œì‘...")
        
        # ì›”ë³„ ë°ì´í„° í•„í„°ë§ (published_date ì‚¬ìš©)
        df_month = df_2025[df_2025[date_column].dt.month == month].copy()
        
        if len(df_month) == 0:
            print(f"   âš ï¸ {month}ì›” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return UTF8JSONResponse(content={
                "success": True,
                "message": f"{month}ì›” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "data": {
                    "month": month,
                    "trends": {
                        f'{month}ì›”': {
                            'top5': [],
                            'total_videos': 0,
                            'top30_videos': 0
                        }
                    },
                    "updated_at": datetime.now().isoformat()
                }
            })
        
        print(f"   ğŸ“Š {month}ì›” ë°ì´í„° í–‰ ìˆ˜: {len(df_month)}")
        
        # ì¤‘ë³µ ì œê±° (video_id ê¸°ì¤€, ì¡°íšŒìˆ˜ ë†’ì€ ê²ƒë§Œ ìœ ì§€)
        df_month = df_month.sort_values(by=views_column, ascending=False) \
                          .drop_duplicates(subset=[video_id_column], keep='first')
        
        # ì¡°íšŒìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        df_sorted = df_month.sort_values(by=views_column, ascending=False)
        
        # ìƒìœ„ 30% ë°ì´í„°ë§Œ ì¶”ì¶œ
        top_30_percent = int(len(df_sorted) * 0.3)
        df_top30 = df_sorted.head(top_30_percent)
        
        print(f"   ğŸ“ˆ ìƒìœ„ 30% ì˜ìƒ ìˆ˜: {len(df_top30)}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ì˜ìƒ ìˆ˜ ì§‘ê³„
        category_counts = df_top30[category_column].value_counts().head(5)
        
        # TOP 5 ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
        top5_categories = []
        for idx, (cat_id, count) in enumerate(category_counts.items(), 1):
            top5_categories.append({
                'rank': idx,
                'category_id': str(int(cat_id)) if pd.notna(cat_id) else None,
                'count': int(count)
            })
        
        print(f"   âœ… {month}ì›” TOP 5 ì¹´í…Œê³ ë¦¬: {[c['category_id'] for c in top5_categories]}")
        
        trend_results = {
            f'{month}ì›”': {
                'top5': top5_categories,
                'total_videos': len(df_month),
                'top30_videos': len(df_top30)
            }
        }
        
        # ê²°ê³¼ ë°˜í™˜
        return UTF8JSONResponse(content={
            "success": True,
            "message": f"{month}ì›” íŠ¸ë Œë“œ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "data": {
                "month": month,
                "trends": trend_results,
                "updated_at": datetime.now().isoformat()
            }
        })
        
    except ImportError:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="kaggle íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install kaggle'ì„ ì‹¤í–‰í•˜ì„¸ìš”."
        )
    except Exception as e:
        import traceback
        error_detail = f"íŠ¸ë Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n{traceback.format_exc()}"
        print(f"âŒ {error_detail}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=error_detail
        )

if __name__ == "__main__":
    import uvicorn
    
    print("=" * 50)
    print("1ë“± ìœ íŠœë²„ ë˜ê¸° FastAPI ì„œë²„ ì‹œì‘")
    print("=" * 50)
    
    # ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists('youtube_analytics.db'):
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € 'python init_database.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ì„¸ìš”.")
        exit(1)
    
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸")
    print("ğŸš€ FastAPI ì„œë²„ ì‹œì‘ ì¤‘...")
    
    import os
    port = int(os.environ.get("PORT", 8001))  # ê¸°ë³¸ê°’ì„ 8001ë¡œ ë³€ê²½
    
    print(f"\nì„œë²„ ì£¼ì†Œ: http://localhost:{port}")
    print(f"API ë¬¸ì„œ: http://localhost:{port}/docs")
    print(f"ReDoc ë¬¸ì„œ: http://localhost:{port}/redoc")
    print("\nì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    print("=" * 50)
    
    uvicorn.run(
        "fastapi_server:app",
        host="0.0.0.0",
        port=port,
        reload=False  # í”„ë¡œë•ì…˜ì—ì„œëŠ” reload=False
    )
